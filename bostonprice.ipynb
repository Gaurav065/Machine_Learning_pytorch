{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "import torch\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.datasets import load_boston\r\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "inputs, targets = load_boston(return_X_y=True)\r\n",
    "inputs  = torch.tensor(inputs, dtype=torch.float32)\r\n",
    "targets = torch.tensor([targets], dtype=torch.float32)\r\n",
    "targets = targets.t()\r\n",
    "\r\n",
    "print(inputs.shape)\r\n",
    "print(targets.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([506, 13])\n",
      "torch.Size([506, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "model = nn.Linear(13,1)\r\n",
    "preds = model(inputs)\r\n",
    "loss_fn = torch.nn.functional.mse_loss\r\n",
    "loss = loss_fn(preds, targets)\r\n",
    "\r\n",
    "opt = torch.optim.SGD(model.parameters(), lr = 1e-6)\r\n",
    "\r\n",
    "def prediction(epoch_num, model, loss_fn):\r\n",
    "    for epoch in range(epoch_num):\r\n",
    "        pred = model(inputs)\r\n",
    "        loss = loss_fn(pred, targets)\r\n",
    "        loss.backward()\r\n",
    "        opt.step()\r\n",
    "        opt.zero_grad()\r\n",
    "        \r\n",
    "        if epoch % 10 == 0:\r\n",
    "            print(loss)\r\n",
    "\r\n",
    "prediction(110, model, loss_fn)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1312.8230, grad_fn=<MseLossBackward>)\n",
      "tensor(510.8845, grad_fn=<MseLossBackward>)\n",
      "tensor(377.5382, grad_fn=<MseLossBackward>)\n",
      "tensor(339.6266, grad_fn=<MseLossBackward>)\n",
      "tensor(316.8173, grad_fn=<MseLossBackward>)\n",
      "tensor(297.7150, grad_fn=<MseLossBackward>)\n",
      "tensor(280.5799, grad_fn=<MseLossBackward>)\n",
      "tensor(265.0359, grad_fn=<MseLossBackward>)\n",
      "tensor(250.9099, grad_fn=<MseLossBackward>)\n",
      "tensor(238.0679, grad_fn=<MseLossBackward>)\n",
      "tensor(226.3919, grad_fn=<MseLossBackward>)\n",
      "tensor(215.7749, grad_fn=<MseLossBackward>)\n",
      "tensor(206.1198, grad_fn=<MseLossBackward>)\n",
      "tensor(197.3386, grad_fn=<MseLossBackward>)\n",
      "tensor(189.3511, grad_fn=<MseLossBackward>)\n",
      "tensor(182.0846, grad_fn=<MseLossBackward>)\n",
      "tensor(175.4730, grad_fn=<MseLossBackward>)\n",
      "tensor(169.4564, grad_fn=<MseLossBackward>)\n",
      "tensor(163.9802, grad_fn=<MseLossBackward>)\n",
      "tensor(158.9949, grad_fn=<MseLossBackward>)\n",
      "tensor(154.4556, grad_fn=<MseLossBackward>)\n",
      "tensor(150.3214, grad_fn=<MseLossBackward>)\n",
      "tensor(146.5552, grad_fn=<MseLossBackward>)\n",
      "tensor(143.1233, grad_fn=<MseLossBackward>)\n",
      "tensor(139.9951, grad_fn=<MseLossBackward>)\n",
      "tensor(137.1428, grad_fn=<MseLossBackward>)\n",
      "tensor(134.5411, grad_fn=<MseLossBackward>)\n",
      "tensor(132.1670, grad_fn=<MseLossBackward>)\n",
      "tensor(129.9998, grad_fn=<MseLossBackward>)\n",
      "tensor(128.0206, grad_fn=<MseLossBackward>)\n",
      "tensor(126.2120, grad_fn=<MseLossBackward>)\n",
      "tensor(124.5585, grad_fn=<MseLossBackward>)\n",
      "tensor(123.0460, grad_fn=<MseLossBackward>)\n",
      "tensor(121.6615, grad_fn=<MseLossBackward>)\n",
      "tensor(120.3933, grad_fn=<MseLossBackward>)\n",
      "tensor(119.2308, grad_fn=<MseLossBackward>)\n",
      "tensor(118.1643, grad_fn=<MseLossBackward>)\n",
      "tensor(117.1850, grad_fn=<MseLossBackward>)\n",
      "tensor(116.2851, grad_fn=<MseLossBackward>)\n",
      "tensor(115.4572, grad_fn=<MseLossBackward>)\n",
      "tensor(114.6948, grad_fn=<MseLossBackward>)\n",
      "tensor(113.9919, grad_fn=<MseLossBackward>)\n",
      "tensor(113.3431, grad_fn=<MseLossBackward>)\n",
      "tensor(112.7434, grad_fn=<MseLossBackward>)\n",
      "tensor(112.1884, grad_fn=<MseLossBackward>)\n",
      "tensor(111.6740, grad_fn=<MseLossBackward>)\n",
      "tensor(111.1965, grad_fn=<MseLossBackward>)\n",
      "tensor(110.7527, grad_fn=<MseLossBackward>)\n",
      "tensor(110.3393, grad_fn=<MseLossBackward>)\n",
      "tensor(109.9537, grad_fn=<MseLossBackward>)\n",
      "tensor(109.5932, grad_fn=<MseLossBackward>)\n",
      "tensor(109.2558, grad_fn=<MseLossBackward>)\n",
      "tensor(108.9392, grad_fn=<MseLossBackward>)\n",
      "tensor(108.6416, grad_fn=<MseLossBackward>)\n",
      "tensor(108.3613, grad_fn=<MseLossBackward>)\n",
      "tensor(108.0967, grad_fn=<MseLossBackward>)\n",
      "tensor(107.8465, grad_fn=<MseLossBackward>)\n",
      "tensor(107.6092, grad_fn=<MseLossBackward>)\n",
      "tensor(107.3838, grad_fn=<MseLossBackward>)\n",
      "tensor(107.1693, grad_fn=<MseLossBackward>)\n",
      "tensor(106.9645, grad_fn=<MseLossBackward>)\n",
      "tensor(106.7687, grad_fn=<MseLossBackward>)\n",
      "tensor(106.5812, grad_fn=<MseLossBackward>)\n",
      "tensor(106.4010, grad_fn=<MseLossBackward>)\n",
      "tensor(106.2277, grad_fn=<MseLossBackward>)\n",
      "tensor(106.0605, grad_fn=<MseLossBackward>)\n",
      "tensor(105.8990, grad_fn=<MseLossBackward>)\n",
      "tensor(105.7427, grad_fn=<MseLossBackward>)\n",
      "tensor(105.5911, grad_fn=<MseLossBackward>)\n",
      "tensor(105.4439, grad_fn=<MseLossBackward>)\n",
      "tensor(105.3006, grad_fn=<MseLossBackward>)\n",
      "tensor(105.1609, grad_fn=<MseLossBackward>)\n",
      "tensor(105.0245, grad_fn=<MseLossBackward>)\n",
      "tensor(104.8911, grad_fn=<MseLossBackward>)\n",
      "tensor(104.7605, grad_fn=<MseLossBackward>)\n",
      "tensor(104.6325, grad_fn=<MseLossBackward>)\n",
      "tensor(104.5069, grad_fn=<MseLossBackward>)\n",
      "tensor(104.3834, grad_fn=<MseLossBackward>)\n",
      "tensor(104.2618, grad_fn=<MseLossBackward>)\n",
      "tensor(104.1422, grad_fn=<MseLossBackward>)\n",
      "tensor(104.0242, grad_fn=<MseLossBackward>)\n",
      "tensor(103.9077, grad_fn=<MseLossBackward>)\n",
      "tensor(103.7928, grad_fn=<MseLossBackward>)\n",
      "tensor(103.6791, grad_fn=<MseLossBackward>)\n",
      "tensor(103.5667, grad_fn=<MseLossBackward>)\n",
      "tensor(103.4555, grad_fn=<MseLossBackward>)\n",
      "tensor(103.3453, grad_fn=<MseLossBackward>)\n",
      "tensor(103.2362, grad_fn=<MseLossBackward>)\n",
      "tensor(103.1280, grad_fn=<MseLossBackward>)\n",
      "tensor(103.0206, grad_fn=<MseLossBackward>)\n",
      "tensor(102.9141, grad_fn=<MseLossBackward>)\n",
      "tensor(102.8084, grad_fn=<MseLossBackward>)\n",
      "tensor(102.7033, grad_fn=<MseLossBackward>)\n",
      "tensor(102.5990, grad_fn=<MseLossBackward>)\n",
      "tensor(102.4953, grad_fn=<MseLossBackward>)\n",
      "tensor(102.3923, grad_fn=<MseLossBackward>)\n",
      "tensor(102.2898, grad_fn=<MseLossBackward>)\n",
      "tensor(102.1879, grad_fn=<MseLossBackward>)\n",
      "tensor(102.0865, grad_fn=<MseLossBackward>)\n",
      "tensor(101.9856, grad_fn=<MseLossBackward>)\n",
      "tensor(101.8852, grad_fn=<MseLossBackward>)\n",
      "tensor(101.7852, grad_fn=<MseLossBackward>)\n",
      "tensor(101.6858, grad_fn=<MseLossBackward>)\n",
      "tensor(101.5867, grad_fn=<MseLossBackward>)\n",
      "tensor(101.4881, grad_fn=<MseLossBackward>)\n",
      "tensor(101.3898, grad_fn=<MseLossBackward>)\n",
      "tensor(101.2920, grad_fn=<MseLossBackward>)\n",
      "tensor(101.1945, grad_fn=<MseLossBackward>)\n",
      "tensor(101.0975, grad_fn=<MseLossBackward>)\n",
      "tensor(101.0007, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}